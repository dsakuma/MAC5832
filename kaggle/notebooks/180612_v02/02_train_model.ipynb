{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo:\n",
    "    * Ensemble using majority voting\n",
    "    * Fix metrics\n",
    "    * Test xgboost\n",
    "    * Test reciprocal\n",
    "    * Create new feature (999)\n",
    "    * Add log reg (improves a little bit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changelog:\n",
    "    * Duplicando dados positivos para melhorar o balanceamento\n",
    "    * Stack with LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '180612_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import transformers\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import make_union\n",
    "from transformers import (ModelTransformer, DataFrameColumnExtractor, ToDictTransformer)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#evaluators\n",
    "#gridcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data/raw/'\n",
    "TRAIN_DATASET_PATH = os.path.join(DATA_DIR, 'train.csv')\n",
    "TEST_DATASET_PATH = os.path.join(DATA_DIR, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATASET_PATH, encoding='utf-8')\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(['y', 'id'], axis=1)\n",
    "y = df_train['y']#.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cv.train_test_split(X,\n",
    "                                                       y,\n",
    "                                                       test_size=0.25,\n",
    "                                                       random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yes = X_train[y_train == 1]\n",
    "y_train_yes = y_train[y_train == 1]\n",
    "\n",
    "X_train = pd.concat([X_train, X_train_yes])\n",
    "y_train = pd.concat([y_train, y_train_yes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bin numeric?\n",
    "\n",
    "pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "\n",
    "skewed: campaign, pdays, previous, emp.var.rate, euribor3m, nr.employed\n",
    "\n",
    "unbalanced data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = [\n",
    "    'job',\n",
    "    'marital',\n",
    "    'education',\n",
    "    'default',\n",
    "    'housing',\n",
    "    'loan',\n",
    "    'contact',\n",
    "    'poutcome',\n",
    "    'month',\n",
    "    'day_of_week'\n",
    "]\n",
    "\n",
    "NUMERIC_FEATURES = [                    \n",
    "    'age',\n",
    "    'pdays',\n",
    "    'emp.var.rate',\n",
    "    'cons.price.idx',\n",
    "    'cons.conf.idx',\n",
    "    'euribor3m',\n",
    "    'campaign',\n",
    "    'previous',\n",
    "    'nr.employed'\n",
    "]\n",
    "\n",
    "TO_APPLY_LOG = [\n",
    "]\n",
    "\n",
    "TO_APPLY_CUBE_ROOT = [\n",
    "\n",
    "]\n",
    "\n",
    "TO_APPLY_RECIPROCAL = [\n",
    "\n",
    "]\n",
    "\n",
    "TO_BIN = [\n",
    "\n",
    "]\n",
    "\n",
    "TRAINING_FEATURES = NUMERIC_FEATURES + CATEGORICAL_FEATURES\n",
    "ALL_COLUMNS = TRAINING_FEATURES + ['id', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_pipeline = make_pipeline(\n",
    "    make_union(\n",
    "        make_pipeline(\n",
    "            make_union(\n",
    "                make_pipeline(\n",
    "                    DataFrameColumnExtractor(NUMERIC_FEATURES),\n",
    "#                     Imputer(strategy=\"median\", axis=0),\n",
    "                ),\n",
    "#                 make_pipeline(\n",
    "#                     DataFrameColumnExtractor(TO_APPLY_RECIPROCAL),\n",
    "# #                     Imputer(strategy=\"median\", axis=0),\n",
    "#                     FunctionTransformer(transformers.sum_1),\n",
    "#                     FunctionTransformer(transformers.apply_reciprocal),\n",
    "#                 )\n",
    "            ),\n",
    "            StandardScaler(),\n",
    "#             PolynomialFeatures()\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DataFrameColumnExtractor(CATEGORICAL_FEATURES),\n",
    "            ToDictTransformer(),\n",
    "            DictVectorizer(sparse=False)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_pipeline = make_pipeline(\n",
    "     make_union(\n",
    "         ModelTransformer(LogisticRegression(random_state=42)),\n",
    "         FunctionTransformer(transformers.all_columns)\n",
    "     ),\n",
    "     GradientBoostingClassifier(random_state=42, max_depth=4) \n",
    ")\n",
    "\n",
    "#      make_union(\n",
    "#          ModelTransformer(SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#             decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "#             max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#             tol=0.001, verbose=False)),\n",
    "#          FunctionTransformer(transformers.all_columns)\n",
    "#      ),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline= Pipeline([\n",
    "    ('features', transformer_pipeline),\n",
    "    ('predictor', predictor_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features', Pipeline(steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline', Pipeline(steps=[('dataframecolumnextractor', DataFrameColumnExtractor(columns=['age', 'pda...100, presort='auto', random_state=42,\n",
       "              subsample=1.0, verbose=0, warm_start=False))]))])"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.95      0.94      8077\n",
      "          1       0.51      0.43      0.47       985\n",
      "\n",
      "avg / total       0.89      0.89      0.89      9062\n",
      "\n",
      "Precision: 0.5053507728894173\n",
      "Recall: 0.43147208121827413\n",
      "F1 Score: 0.8885265478255482\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Precision: \"+ str(metrics.precision_score(y_test, y_pred)))\n",
    "print(\"Recall: \"+ str(metrics.recall_score(y_test, y_pred)))\n",
    "print(\"F1 Score: \"+ str(metrics.f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data/raw/'\n",
    "TRAIN_DATASET_PATH = os.path.join(DATA_DIR, 'train.csv')\n",
    "TEST_DATASET_PATH = os.path.join(DATA_DIR, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATASET_PATH, encoding='utf-8')\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['y', 'id'], axis=1)\n",
    "y_train = df_train['y']#.astype(bool)\n",
    "\n",
    "X_test = df_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yes = X_train[y_train == 1]\n",
    "y_train_yes = y_train[y_train == 1]\n",
    "\n",
    "X_train = pd.concat([X_train, X_train_yes])\n",
    "y_train = pd.concat([y_train, y_train_yes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features', Pipeline(steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline', Pipeline(steps=[('dataframecolumnextractor', DataFrameColumnExtractor(columns=['age', 'pda...100, presort='auto', random_state=42,\n",
       "              subsample=1.0, verbose=0, warm_start=False))]))])"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_submission = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_submission = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission file\n",
    "SUBMISSION_DATA_DIR = '../../data/submission/'\n",
    "SUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DATA_DIR, VERSION+'.csv')\n",
    "\n",
    "df_submission = pd.DataFrame({'id':ids_submission, 'y':pred_submission})\n",
    "df_submission.to_csv(SUBMISSION_FILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9062 entries, 0 to 9061\n",
      "Data columns (total 2 columns):\n",
      "id    9062 non-null int64\n",
      "y     9062 non-null int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 141.7 KB\n"
     ]
    }
   ],
   "source": [
    "df_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
