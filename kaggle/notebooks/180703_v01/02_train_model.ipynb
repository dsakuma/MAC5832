{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo:\n",
    "    * bin\n",
    "    * other cat encoding\n",
    "    * 999 -> mean or median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done:\n",
    "    * new feature pdays == 999 (not improve)\n",
    "    * test all classifier algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changelog:\n",
    "    * separate transformer from classification pipeline\n",
    "    * use gridsearchcv\n",
    "    * use cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '180703_v01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import transformers\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import make_union\n",
    "from transformers import (ModelTransformer, DataFrameColumnExtractor, ToDictTransformer)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data/raw/'\n",
    "TRAIN_DATASET_PATH = os.path.join(DATA_DIR, 'train.csv')\n",
    "TEST_DATASET_PATH = os.path.join(DATA_DIR, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATASET_PATH, encoding='utf-8')\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(['y', 'id'], axis=1)\n",
    "y = df_train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_yes = X_train[y_train == 1]\n",
    "# y_train_yes = y_train[y_train == 1]\n",
    "\n",
    "# X_train = pd.concat([X_train, X_train_yes])\n",
    "# y_train = pd.concat([y_train, y_train_yes])\n",
    "\n",
    "# X_train = pd.concat([X_train, X_train_yes])\n",
    "# y_train = pd.concat([y_train, y_train_yes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = [\n",
    "    'job',\n",
    "    'marital',\n",
    "    'education',\n",
    "    'default',\n",
    "    'housing',\n",
    "    'loan',\n",
    "    'contact',\n",
    "    'poutcome',\n",
    "    'month',\n",
    "    'day_of_week'\n",
    "]\n",
    "\n",
    "NUMERIC_FEATURES = [                    \n",
    "    'age',\n",
    "#     'campaign',\n",
    "    'pdays',\n",
    "#     'previous',\n",
    "    'emp.var.rate',\n",
    "    'cons.price.idx',\n",
    "    'cons.conf.idx',\n",
    "    'euribor3m',\n",
    "    'nr.employed'\n",
    "]\n",
    "\n",
    "TO_APPLY_LOG = [\n",
    "]\n",
    "\n",
    "TO_APPLY_CUBE_ROOT = [\n",
    "\n",
    "]\n",
    "\n",
    "TO_APPLY_RECIPROCAL = [\n",
    "    'campaign',\n",
    "    'previous'\n",
    "]\n",
    "\n",
    "TO_BIN = [\n",
    "\n",
    "]\n",
    "\n",
    "TRAINING_FEATURES = NUMERIC_FEATURES + CATEGORICAL_FEATURES\n",
    "ALL_COLUMNS = TRAINING_FEATURES + ['id', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = make_pipeline(\n",
    "    make_pipeline(\n",
    "\n",
    "        make_union(\n",
    "            make_pipeline(\n",
    "                make_union(\n",
    "                    make_pipeline(\n",
    "                        DataFrameColumnExtractor(NUMERIC_FEATURES),\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        DataFrameColumnExtractor(TO_APPLY_RECIPROCAL),\n",
    "                        FunctionTransformer(transformers.sum_1),\n",
    "                        FunctionTransformer(transformers.apply_reciprocal),\n",
    "                    )\n",
    "                ),\n",
    "                StandardScaler(),\n",
    "            ),\n",
    "            make_pipeline(\n",
    "                DataFrameColumnExtractor(CATEGORICAL_FEATURES),\n",
    "                ToDictTransformer(),\n",
    "                DictVectorizer(sparse=False)\n",
    "            ),\n",
    "#             make_pipeline(\n",
    "#                 DataFrameColumnExtractor(['pdays']),\n",
    "#                 FunctionTransformer(transformers.extract_not_prev_contacted)\n",
    "#             ),\n",
    "        ),\n",
    "        SelectKBest(f_classif, k=55),\n",
    "#         PolynomialFeatures(interaction_only=True)\n",
    "    )\n",
    ")\n",
    "\n",
    "# DataFrameColumnExtractor(to_bin),\n",
    "# FunctionTransformer(transformers.bin_data, kw_args={'columns': to_bin, 'bins': bins}),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Pipeline([\n",
    "    ('voting', VotingClassifier(estimators=[\n",
    "                ('gbc', GradientBoostingClassifier(random_state=42)), \n",
    "                ('xgb', XGBClassifier(random_state=42)), \n",
    "                ('lr', LogisticRegression(random_state=42)),\n",
    "                ('rf', RandomForestClassifier(random_state=42)),\n",
    "                ('gnb', GaussianNB()),\n",
    "                ('mlp', MLPClassifier(random_state=42, solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2)))\n",
    "               ], voting='soft'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline= Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('predictor', predictor)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipeline, X, y, cv=5, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8869241113147683"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cv.train_test_split(X,\n",
    "                                                       y,\n",
    "                                                       test_size=0.25,\n",
    "                                                       random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Precision: \"+ str(metrics.precision_score(y_test, y_pred)))\n",
    "print(\"Recall: \"+ str(metrics.recall_score(y_test, y_pred)))\n",
    "print(\"F1 Score: \"+ str(metrics.f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params = {\n",
    "    'voting__lr__C': [0.1, 1, 10],\n",
    "#     'voting__gbc__n_estimators': [50, 100, 150],\n",
    "#     'voting__gbc__learning_rate':[0.01,0.1,1],\n",
    "#     'voting__gbc__max_depth': [2,3,4],\n",
    "#     'voting__gbc__min_samples_split': [2,3],\n",
    "    'voting__rf__n_estimators': [5, 10, 15],\n",
    "    'voting__rf__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'voting__rf__criterion' :['gini', 'entropy'],\n",
    "    'voting__mlp__solver': ['lbfgs', 'adam', 'sgd'], \n",
    "    'voting__mlp__max_iter': [150,200,250], \n",
    "    'voting__mlp__alpha':  [0.0001, 0.001, 0.01],\n",
    "    'voting__xgb__learning_rate': [0.03, 0.3, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid = grid.fit(transformer.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X, y)\n",
    "pred_submission = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_submission = df_submission['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission file\n",
    "SUBMISSION_DATA_DIR = '../../data/submission/'\n",
    "SUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DATA_DIR, VERSION+'.csv')\n",
    "\n",
    "df_submission = pd.DataFrame({'id':ids_submission, 'y':pred_submission})\n",
    "df_submission.to_csv(SUBMISSION_FILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
